{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWMBD1TJEm_z"
   },
   "source": [
    "# AnTeDe Lab 3: Sentiment Analysis - Part C\n",
    "\n",
    "## Session goal\n",
    "The goal of this session is to run document-level sentiment analysis on the IMDB movie review corpus by applying supervised text classification techniques. We begin by wrangling the IMBD corpus into lists, exactly like in 3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzLBc5xkEm_1",
    "outputId": "d151ec9e-c095-45eb-9c98-24cfffdd44d8",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:34.385550400Z",
     "start_time": "2024-03-16T10:00:17.148236600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to C:\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random, nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "corpus = [' '.join(movie_reviews.words(fileid)) \\\n",
    "          for category in movie_reviews.categories() \\\n",
    "          for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "labels = [category \\\n",
    "          for category in movie_reviews.categories() \\\n",
    "          for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9BM7VxVEm_2"
   },
   "source": [
    "**scikit-learn** enables us the split the corpus into a training corpus and a test corpus. The parameter *test-size* is the desired ratio of the test corpus size to the training corpus size. The paramenter *random_state* ensures reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NZBIzJlYEm_3",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:34.400906800Z",
     "start_time": "2024-03-16T10:00:34.385550400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_corpus, test_corpus, training_labels, test_labels = train_test_split(\n",
    "        corpus, labels, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rr1l2eFKEm_4"
   },
   "source": [
    "We reuse our helper function **get_metrics** from Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9pIElPoLEm_4",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:34.400906800Z",
     "start_time": "2024-03-16T10:00:34.392285700Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predicted_labels):\n",
    "        from sklearn import metrics\n",
    "        import numpy as np\n",
    "        print ('Accuracy:', np.round(\n",
    "            metrics.accuracy_score(true_labels,\n",
    "            predicted_labels), 3))\n",
    "        \n",
    "        from sklearn.metrics import classification_report\n",
    "        print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7Pq6IbHEm_4"
   },
   "source": [
    "Now we are going to use a MNB classifier for sentiment analysis. **CountVectorizer**'s parameter **binary** replaces token counts with binary values if set to True. In sentiment analysis, the number of occurrences of a token may not be as important as its presence or absence, so setting it to True may be a good idea, but let's perform 10-fold cross-validation to find out whether it really is. We want the mean to be as high as possible and the standard deviation to be as low as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhewYg1fEm_6",
    "outputId": "ad987bff-3845-478b-aa58-250fe65417c5",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:40.536893300Z",
     "start_time": "2024-03-16T10:00:34.397907600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802\n",
      "0.023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_pipeline_1 = Pipeline([ ('vectorizer', CountVectorizer(binary = False, stop_words='english')),\\\n",
    "                ('classifier', MultinomialNB())])  \n",
    "    \n",
    "scores = cross_val_score(mnb_pipeline_1, training_corpus, training_labels, cv=10)\n",
    "import numpy as np\n",
    "print (round(np.mean(scores), 3))\n",
    "print (round(np.std(scores), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8cQn4YREm_6",
    "outputId": "b857d8ec-fcc4-4a83-d64a-0d15522adf76",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:46.686249Z",
     "start_time": "2024-03-16T10:00:40.528373800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833\n",
      "0.028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mnb_pipeline_2 = Pipeline([ ('vectorizer', CountVectorizer(binary = True, stop_words='english')),\\\n",
    "                ('classifier', MultinomialNB())])  \n",
    "    \n",
    "scores = cross_val_score(mnb_pipeline_2, training_corpus, training_labels, cv=10)\n",
    "import numpy as np\n",
    "print (round(np.mean(scores), 3))\n",
    "print (round(np.std(scores), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPGtR9DYEm_7"
   },
   "source": [
    "Based on your 10-fold cross-validation results, choose one of the two pipelines, train it, run it, and analyze its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0QZHhSyEm_8",
    "outputId": "76ade4de-0da9-458c-ae26-91a0f6e041f9",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:47.488794600Z",
     "start_time": "2024-03-16T10:00:46.677733600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.81      0.82       198\n",
      "         pos       0.82      0.84      0.83       202\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.83      0.82      0.82       400\n",
      "weighted avg       0.83      0.82      0.82       400\n"
     ]
    }
   ],
   "source": [
    "# BEGIN_REMOVE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mnb_pipeline_2.fit(training_corpus, training_labels) \n",
    "predicted_labels = mnb_pipeline_2.predict(test_corpus)\n",
    "get_metrics(true_labels=test_labels,\n",
    "        predicted_labels=predicted_labels)\n",
    "# END_REMOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFy4_B8PEm_9"
   },
   "source": [
    "Now let's train a Maximum Entropy classifier using the **LogisticRegression** module from **scikit-learn**. Please complete the code to train and run the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maE5pKrbEm_9",
    "outputId": "9dd5b5a1-15c1-4b54-8aec-4c0f4e3ef8e1",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:49.844684Z",
     "start_time": "2024-03-16T10:00:47.483788800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.81      0.83       198\n",
      "         pos       0.82      0.86      0.84       202\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.83      0.83       400\n",
      "weighted avg       0.84      0.83      0.83       400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "vectorizer = CountVectorizer(binary = True, stop_words='english')\n",
    "classifier = LogisticRegressionCV()\n",
    "maxent_pipeline = make_pipeline(vectorizer, classifier)\n",
    "\n",
    "\n",
    "# BEGIN_REMOVE\n",
    "maxent_pipeline.fit(training_corpus, training_labels) \n",
    "predicted_labels = maxent_pipeline.predict(test_corpus)\n",
    "get_metrics(true_labels=test_labels,\n",
    "        predicted_labels=predicted_labels)\n",
    "# END_REMOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6rW2zzqEm__"
   },
   "source": [
    "It seems reasonable to get the classifier to focus on sentiment words. Let's begin by extracting a list of positive words and a list of negative words as we did in Lab 3b. "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! mkdir Words"
   ],
   "metadata": {
    "id": "59c9nZ-dI_XJ",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:49.856749800Z",
     "start_time": "2024-03-16T10:00:49.837173Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "url_neg = \"https://ptrckprry.com/course/ssd/data/negative-words.txt\"\n",
    "url_pos = \"https://ptrckprry.com/course/ssd/data/positive-words.txt\"\n",
    "\n",
    "def download_from_url(url, filepath):\n",
    "  import requests\n",
    "  r = requests.get(url)\n",
    "  with open(filepath, 'wb') as f:\n",
    "      f.write(r.content)\n",
    "\n",
    "download_from_url (url_pos, 'Words/positive-words.txt')      \n",
    "download_from_url (url_neg, 'Words/negative-words.txt')  "
   ],
   "metadata": {
    "id": "accTGyETJCon",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:50.766494500Z",
     "start_time": "2024-03-16T10:00:49.858747300Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9ZpfsP3AEnAA",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:50.777316500Z",
     "start_time": "2024-03-16T10:00:50.768497800Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('Words/positive-words.txt', errors='ignore') as opened:\n",
    "    contents=opened.read()\n",
    "contents_lines=['a+'] + contents.split('a+')[1].split('\\n')\n",
    "\n",
    "positive_words = [x for x in contents_lines if len(x)>0]\n",
    "\n",
    "\n",
    "with open('Words/negative-words.txt', errors='ignore') as opened:\n",
    "    contents=opened.read()\n",
    "contents_lines=['2-faced'] + contents.split('2-faced')[1].split('\\n')\n",
    "\n",
    "negative_words = [x for x in contents_lines if len(x)>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJBb9l4REnAA"
   },
   "source": [
    "Now, let's write a function to remove non-sentiment tokens from our corpus. Once we have it, we'll run it on the training corpus and the test corpus to transform them into sentiment-only corpora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JNMZKTKPEnAB",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:56.065155800Z",
     "start_time": "2024-03-16T10:00:50.774311200Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN_REMOVE\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_non_sentiment_tokens(corpus):\n",
    "    sentiment_only_corpus=[]\n",
    "    for document in corpus:\n",
    "\n",
    "        document_words = set(word for word in word_tokenize(document))\n",
    "        sentiment_words = list(document_words.intersection(positive_words))+\\\n",
    "                          list(document_words.intersection(negative_words))\n",
    "        sentiment_only_corpus.append(' '.join(sentiment_words))\n",
    "    return sentiment_only_corpus   \n",
    "    \n",
    "sentiment_only_training_corpus = remove_non_sentiment_tokens(training_corpus)\n",
    "sentiment_only_test_corpus = remove_non_sentiment_tokens(test_corpus)\n",
    "# END_REMOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzPfdxg4EnAB"
   },
   "source": [
    "Now, please train **maxent_pipeline** on the **sentiment_only_training_corpus** and test it on the **sentiment_only_test_corpus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bs1qOZ2EnAC",
    "outputId": "1bebb5a6-f954-4038-e709-828c315e941c",
    "ExecuteTime": {
     "end_time": "2024-03-16T10:00:56.333505300Z",
     "start_time": "2024-03-16T10:00:56.066159600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.78      0.81       198\n",
      "         pos       0.80      0.86      0.83       202\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.82      0.82      0.82       400\n",
      "weighted avg       0.82      0.82      0.82       400\n"
     ]
    }
   ],
   "source": [
    "# BEGIN_REMOVE\n",
    "maxent_pipeline.fit(sentiment_only_training_corpus, training_labels) \n",
    "\n",
    "predicted_labels = maxent_pipeline.predict(sentiment_only_test_corpus)\n",
    "get_metrics(true_labels=test_labels,\n",
    "        predicted_labels=predicted_labels)\n",
    "# END_REMOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hj1B7orhEnAC"
   },
   "source": [
    "Open question: what do you think about the performance variation? Is it what close to what you would have expected? Why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
