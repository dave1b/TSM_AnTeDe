{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "J_rT74OE3u7X"
   },
   "source": [
    "![MSE Logo](https://moodle.msengineering.ch/pluginfile.php/1/core_admin/logo/0x150/1643104191/logo-mse.png)\n",
    "\n",
    "# AnTeDe Lab 4: Search Engine with the Vector Space Model\n",
    "\n",
    "## Summary\n",
    "The aim of this lab is to build a simple document search engine based on TF-IDF document vectors. \n",
    "\n",
    "The lab is inspired by a notebook designed by [Kavita Ganesan](https://github.com/kavgan/nlp-in-practice/blob/master/TF-IDF/Keyword%20Extraction%20with%20TF-IDF%20and%20SKlearn.ipynb).\n",
    "\n",
    "<font color='green'>Please answer the questions in green within this notebook, and submit the completed notebook under the corresponding homework on Moodle.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1678792631556,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "1HfzVuMr3u7b",
    "outputId": "55e38a84-e840-49f6-c05a-76e0405ad00e",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:04.893977Z",
     "start_time": "2024-03-20T14:51:03.940428Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/davebrunner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/davebrunner/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/davebrunner/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/davebrunner/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/davebrunner/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk  # on Colab, you mind find it helpful to run nltk.download('popular') to install packages\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from gensim import models, corpora, similarities\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:04.920128Z",
     "start_time": "2024-03-20T14:51:04.894783Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import TextProcessor.py from local directory structure\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../week 1'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from TextPreprocessor import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_-0tNus3u7d"
   },
   "source": [
    "The data used in this lab is a set of 300 documents selected from the Australian Broadcasting Corporation's news mail service. It consists of texts of headline stories from around the years 2000-2001.  This is a shortened version of the Lee Background Corpus [described here](http://www.socsci.uci.edu/~mdlee/lee_pincombe_welsh_document.PDF).  It is available as test data in the **gensim** package, so you do not need to download it separately.\n",
    "\n",
    "The following code will load the documents into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1678792638008,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "YPD9lzy93u7e",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:04.923124Z",
     "start_time": "2024-03-20T14:51:04.920584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code inspired from:\n",
    "# https://github.com/bhargavvader/personal/blob/master/notebooks/text_analysis_tutorial/topic_modelling.ipynb\n",
    "\n",
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])\n",
    "lee_train_file = test_data_dir + os.sep + 'lee_background.cor'\n",
    "text = open(lee_train_file).read().splitlines()\n",
    "data_df = pd.DataFrame({'text': text})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hJbDDf633u7f"
   },
   "source": [
    "The following code will run our in-house Text Preprocessor provided in the `TextPreprocessor.py` file, and documented in the `MSE_AnTeDe_TextPreprocessingDemo.ipynb` notebook provided in Lab 1 (see Lab 1 archive on Moodle for both files).\n",
    "\n",
    "<font color='green'> **Question**: Please enhance the code by adding special characters such as e.g., \" ' ' \" as stopwords and uses adjective and noun POS tag sets in the TextPreprocessor function.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1678792638009,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "pUnbeSRb3u7g",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:05.260013Z",
     "start_time": "2024-03-20T14:51:04.924114Z"
    }
   },
   "outputs": [],
   "source": [
    "language = 'english'\n",
    "stop_words = set(stopwords.words(language))\n",
    "# Extend the list here:\n",
    "stop_words.update(\n",
    "    [',', '.', '!', '?', ';', ':', '(', ')', '[', ']', '{', '}', '``', \"''\", '\"\"', '``', \"''\", '\"\"', '’', '“', '”', '‘',\n",
    "     '—', '–', '…', '•', '·', '°', '€', '£', '¥', '¢', '§', '©', '®', '™', '¶', '†', '‡', '‰', '№', 'Ω', '℮', '→', '↔'])\n",
    "processor = TextPreprocessor(  # these are only a few of the options of TextPreprocessor (see code for more)\n",
    "    language=language,\n",
    "    pos_tags={wordnet.ADJ, wordnet.NOUN},\n",
    "    stopwords=stop_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 21824,
     "status": "ok",
     "timestamp": 1678792659830,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "2DAZdRyF3u7h",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.738238Z",
     "start_time": "2024-03-20T14:51:05.260609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davebrunner/.local/share/virtualenvs/TSM_AnTeDe-RXa4k3O7/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "data_df['processed'] = processor.transform(data_df['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at a few examples of processed texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1678792659830,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "xS8OabTb3u7i",
    "outputId": "ee87ed46-0d7b-47f0-92aa-d5b982a1dffd",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.741203Z",
     "start_time": "2024-03-20T14:51:07.739117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new report suggests the costs of an aging Australian population have been exaggerated. The report issued by the Australia Institute says a detailed examination of population and health data shows an aging population will not create an unsustainable burden on a shrinking workforce. Far from being an economic and social burden, it found the majority of older people enjoyed healthy and independent lives, many making financial contributions to their families and participating in voluntary community activities. The paper challenges the assumption an older population will see health costs rise to unsustainable levels. It says rising health costs are caused mainly by factors other than aging such as the growth of medical technology, rising consumer demand and escalating prices. \n",
      "new report suggests cost australian population exaggerated report australia institute detailed examination population health data show population create unsustainable burden workforce economic social burden found majority old people healthy independent life many financial contribution family voluntary community activity paper challenge assumption old population health cost rise unsustainable level health cost factor growth medical technology consumer demand price\n"
     ]
    }
   ],
   "source": [
    "print(data_df['text'].iloc[136])\n",
    "# see the single 'a' is missing in the processed and removed by the TextPreprocessor\n",
    "print(data_df['processed'].iloc[136])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1678792659830,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "050vP9dMbMAL",
    "outputId": "42dead0a-a9ee-4514-d0e5-0f78b0df7adf",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.747448Z",
     "start_time": "2024-03-20T14:51:07.741715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  \\\n0  Hundreds of people have been forced to vacate ...   \n1  Indian security forces have shot dead eight su...   \n2  The national road toll for the Christmas-New Y...   \n3  Argentina's political and economic crisis has ...   \n4  Six midwives have been suspended at Wollongong...   \n\n                                           processed  \n0  hundred people vacate home southern highland n...  \n1  indian security force shot dead eight militant...  \n2  national road toll christmas-new year holiday ...  \n3  argentina 's political economic crisis resigna...  \n4  six midwife wollongong hospital south sydney i...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>processed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hundreds of people have been forced to vacate ...</td>\n      <td>hundred people vacate home southern highland n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Indian security forces have shot dead eight su...</td>\n      <td>indian security force shot dead eight militant...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The national road toll for the Christmas-New Y...</td>\n      <td>national road toll christmas-new year holiday ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Argentina's political and economic crisis has ...</td>\n      <td>argentina 's political economic crisis resigna...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Six midwives have been suspended at Wollongong...</td>\n      <td>six midwife wollongong hospital south sydney i...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM1Fzwnn3u7j"
   },
   "source": [
    "## Generation of document vectors with [Scikit-learn](https://scikit-learn.org/stable)\n",
    "\n",
    "We will use the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) class from scikit-learn to create a vocabulary and generate word counts or *Term Frequencies* (TF).\n",
    "    \n",
    "The result is a  matrix representation of the counts: each column represents a _word_ in the vocabulary and each row represents a document in our dataset: the cell values are the word counts of the word in the document. \n",
    "\n",
    "The matrix is very sparse, because all words not appearing in a document have 0 counts.\n",
    "\n",
    "Recommended reading for usage and differences of scikit-learn’s Tfidftransformer and Tfidfvectorizer: \n",
    "\n",
    "https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/\n",
    "\n",
    "In order to start using TfidfTransformer you will first have to create a CountVectorizer to count the number of words (term frequency), limit your vocabulary size, apply stop words and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1678792659830,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "Rd5WqzEl3u7k",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.761164Z",
     "start_time": "2024-03-20T14:51:07.748018Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=3000)  # keep only the 3000 most frequent words in the corpus\n",
    "word_count_vector = cv.fit_transform(data_df['processed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgg6rP7k3u7l"
   },
   "source": [
    "Let's look at some words from our vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1678792659830,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "IfIC--5Y3u7l",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.763916Z",
     "start_time": "2024-03-20T14:51:07.761837Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1678792659831,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "-U7E6PqE3u7l",
    "outputId": "cbc4d19c-4b04-4169-e5c8-febdf634a05c",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.767566Z",
     "start_time": "2024-03-20T14:51:07.765610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of features 3000\n",
      "['sri' 'st' 'stabbed' 'stabilise' 'stability']\n",
      "[1315]\n",
      "hundred\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of features {len(feature_names)}\")  # has the max_features value been reached?\n",
    "print(feature_names[2500:2505])  # try various slices\n",
    "print(np.where(feature_names == 'hundred')[0])  # find a word's index\n",
    "print(feature_names[1315])  # find a word corresponding to an index\n",
    "# print(cv.vocabulary_.items())\n",
    "\n",
    "# print(cv.vocabulary_.keys())\n",
    "# print(cv.vocabulary_.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VO-DTsR_YgFg"
   },
   "source": [
    "Now, let’s check the shape of the term-document matrix, which should contain 300 documents from the Lee Corpus and 3000 terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1678792659831,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "jG0FYa-hYsQF",
    "outputId": "8e0ad3ca-7d78-4b29-807a-aa0992e1ca85",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.770008Z",
     "start_time": "2024-03-20T14:51:07.768193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(300, 3000)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1678792659831,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "l8qwp0VXuUW4",
    "outputId": "1c9a29a1-4e86-4480-9ba3-6d2dc099a059",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.773113Z",
     "start_time": "2024-03-20T14:51:07.770539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'hundred': 18}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output word counts for a particular word  \n",
    "count_list = np.asarray(word_count_vector.sum(axis=0))[0]\n",
    "word_count_dict = dict(zip(feature_names, count_list))\n",
    "\n",
    "res = {k: v for k, v in word_count_dict.items() if k.startswith('hundred')}\n",
    "# res = {k: v for k, v in word_count_dict.items() if k.startswith('people')}\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3akOYQ1b3u7m"
   },
   "source": [
    "**TfidfTransformer to Compute Inverse Document Frequency (IDF)**\n",
    "\n",
    "We now use the (sparse) matrix generated by `CountVectorizer` to compute the IDF values of each word.  Note that the IDF should in reality be based on a large and representative corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1678792659831,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "h98ABx053u7n",
    "outputId": "525d209b-0b7d-4cc3-91aa-762c3e43a5f4",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.776948Z",
     "start_time": "2024-03-20T14:51:07.773575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TfidfTransformer()",
      "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfTransformer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfTransformer()</pre></div> </div></div></div></div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8EwZDDy3u7n"
   },
   "source": [
    "The IDF values are stored in the `idf_` field of the `TfidfTransformer`.  It has the same size as the array of feature names (words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1678792659831,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "bHTO_vsr3u7n",
    "outputId": "222db547-8dce-4187-e89d-59645409ee05",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.779035Z",
     "start_time": "2024-03-20T14:51:07.777482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(tfidf_transformer.idf_))  # check length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x_pCo3OZSx0"
   },
   "source": [
    "To get a glimpse of how the IDF values look, we are going to print it by placing the IDF values in a python DataFrame. The values will be sorted in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1678792659831,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "_KgXfs-eZD1n",
    "outputId": "4616c1aa-caed-4da4-8622-8da898d8e53e",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.784841Z",
     "start_time": "2024-03-20T14:51:07.779512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.81673851]\n"
     ]
    },
    {
     "data": {
      "text/plain": "            idf_weights\nmr             1.911320\nyear           2.015762\naustralian     2.072381\nnew            2.101940\none            2.122143\n...                 ...\nbuchanan       6.013963\nsteep          6.013963\nsteinlager     6.013963\nsri            6.013963\nkirribilli     6.013963\n\n[3000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idf_weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mr</th>\n      <td>1.911320</td>\n    </tr>\n    <tr>\n      <th>year</th>\n      <td>2.015762</td>\n    </tr>\n    <tr>\n      <th>australian</th>\n      <td>2.072381</td>\n    </tr>\n    <tr>\n      <th>new</th>\n      <td>2.101940</td>\n    </tr>\n    <tr>\n      <th>one</th>\n      <td>2.122143</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>buchanan</th>\n      <td>6.013963</td>\n    </tr>\n    <tr>\n      <th>steep</th>\n      <td>6.013963</td>\n    </tr>\n    <tr>\n      <th>steinlager</th>\n      <td>6.013963</td>\n    </tr>\n    <tr>\n      <th>sri</th>\n      <td>6.013963</td>\n    </tr>\n    <tr>\n      <th>kirribilli</th>\n      <td>6.013963</td>\n    </tr>\n  </tbody>\n</table>\n<p>3000 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a single idf value \n",
    "print(tfidf_transformer.idf_[np.where(cv.get_feature_names_out() == 'hundred')])  # check IDF value of a word\n",
    "\n",
    "# print idf values in a data frame \n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names_out(), columns=[\"idf_weights\"])\n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QGDruZ243u7o"
   },
   "source": [
    "**We define here two helper functions:**\n",
    " * the first one is a sorting function for the columns of a sparse matrix in COOrdinate format (a.k.a \"ijv\" or \"triplet\" format [explained here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html));\n",
    " * the second one extracts the feature names (*words*) and their TF-IDF values from the sorted list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1678792659831,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "6o1XWhnO3u7o",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.788019Z",
     "start_time": "2024-03-20T14:51:07.785318Z"
    }
   },
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and TF-IDF score of top n items from sorted list\"\"\"\n",
    "\n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "\n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    results = {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]] = score_vals[idx]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mv-AZ-v03u7o"
   },
   "source": [
    "We now select a document for which we will generate TF-IDF values.  <font color=\"green\">Please select a random document of your choice between 0 and 300.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1678792659832,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "vCX0MvIC3u7o",
    "outputId": "08716b8f-a4c1-44b3-829c-bc3daaad96b4",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.790223Z",
     "start_time": "2024-03-20T14:51:07.788638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph Gutnick, the saviour and former president of the Melbourne Football Club, has failed in his bid to be re-elected as president, after stepping down earlier this year. He was also dumped from the board. Gabriel Szondy and his Team Vision ticket comprehensively beat Mr Gutnick's Melbourne First ticket, in an election which saw 75 per cent of the club's more than 16,000 members vote. Mr Szondy says he is pleased it was such a decisive victory. \"We're very happy that the members have voted so overwhelmingly in support of the ticket and it hasn't been cherry-picked,\" he said. He attributed the victory to both the presence of former Demon's great Robert Flower on his ticket and Mr Gutnick's ill-timed attempt to settle the presidency issue mid-season. Arriving at the club's annual general meeting last night, Mr Gutnick said regardless of the outcome, he expected the result to unite the club. \"It shouldn't divide the club, we should drop all our differences and work together.\" \n",
      "joseph gutnick saviour former president melbourne football club bid re-elected president year dumped board gabriel szondy team vision ticket beat mr gutnick 's melbourne ticket election saw per cent club 's 16,000 member vote mr szondy pleased decisive victory happy member support ticket cherry-picked victory presence former demon 's great robert flower ticket mr gutnick 's ill-timed attempt presidency issue mid-season club 's annual general meeting last night mr gutnick outcome result unite club divide club drop difference work\n"
     ]
    }
   ],
   "source": [
    "doc_orig = data_df['text'].iloc[111]\n",
    "doc_processed = data_df['processed'].iloc[111]\n",
    "print(doc_orig)\n",
    "print(doc_processed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq5v6Qwj3u7p"
   },
   "source": [
    "The next instruction generates the vector of TF-IDF values for the document using the `tfidf_transformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1678792659832,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "ymfc56jU3u7p",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.792779Z",
     "start_time": "2024-03-20T14:51:07.790735Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_idf_vector = tfidf_transformer.transform(cv.transform([doc_processed]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SNu8SobW3u7p"
   },
   "source": [
    "Next, we sort the words in the `tf_idf_vector` by decreasing TF-IDF values, first transforming the vector into a coordinate format ('coo'), and then applying our sorting function from above.  We then extract the words with the top 10 scores (and the scores) for the selected document using our second helper function from above and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1678792659832,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "8FhBHurc3u7q",
    "outputId": "84f56856-f886-49c0-a0b3-437a72af033f",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.795271Z",
     "start_time": "2024-03-20T14:51:07.793398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph Gutnick, the saviour and former president of the Melbourne Football Club, has failed in his bid to be re-elected as president, after stepping down earlier this year. He was also dumped from the board. Gabriel Szondy and his Team Vision ticket comprehensively beat Mr Gutnick's Melbourne First ticket, in an election which saw 75 per cent of the club's more than 16,000 members vote. Mr Szondy says he is pleased it was such a decisive victory. \"We're very happy that the members have voted so overwhelmingly in support of the ticket and it hasn't been cherry-picked,\" he said. He attributed the victory to both the presence of former Demon's great Robert Flower on his ticket and Mr Gutnick's ill-timed attempt to settle the presidency issue mid-season. Arriving at the club's annual general meeting last night, Mr Gutnick said regardless of the outcome, he expected the result to unite the club. \"It shouldn't divide the club, we should drop all our differences and work together.\"  \n",
      " {'club': 0.466, 'ticket': 0.44, 'gutnick': 0.44, 'szondy': 0.22, 'victory': 0.151, 'mr': 0.14, 'melbourne': 0.125, 'former': 0.123, 'saviour': 0.11, 'president': 0.109}\n"
     ]
    }
   ],
   "source": [
    "sorted_items = sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "topn_words = extract_topn_from_vector(feature_names, sorted_items, 10)\n",
    "\n",
    "print(doc_orig, '\\n', topn_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sauSc-w_cvtm"
   },
   "source": [
    "Alternatively the TF-IDF values of the first document can be inspected by placing the TF-IDF scores from the first document into a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1678792659832,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "GhF-b2f0cWsO",
    "outputId": "01662749-6924-4dcf-fd8a-5788385088ab",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.798551Z",
     "start_time": "2024-03-20T14:51:07.795719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the data frame is:  (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names_out()\n",
    "#get tfidf vector for first document \n",
    "first_document_vector = tf_idf_vector[0]\n",
    "#densify and print the scores \n",
    "df_firstdoc = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "print(\"the size of the data frame is: \", df_firstdoc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1678792659832,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "BAIvkVDrf5WA",
    "outputId": "9fee5ea6-b247-4e18-f861-e35451b8c5dd",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.802169Z",
     "start_time": "2024-03-20T14:51:07.799056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               tfidf\nclub        0.465806\nticket      0.439626\ngutnick     0.439626\nszondy      0.219813\nvictory     0.151398\nmr          0.139719\nmelbourne   0.124684\nformer      0.123354\nsaviour     0.109907\npresident   0.109415\nmember      0.105209\ngabriel     0.102497\ndumped      0.102497\npresidency  0.102497\ndecisive    0.097239\npleased     0.097239\nelected     0.093161\npicked      0.093161\nill         0.093161\nhappy       0.089829",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>club</th>\n      <td>0.465806</td>\n    </tr>\n    <tr>\n      <th>ticket</th>\n      <td>0.439626</td>\n    </tr>\n    <tr>\n      <th>gutnick</th>\n      <td>0.439626</td>\n    </tr>\n    <tr>\n      <th>szondy</th>\n      <td>0.219813</td>\n    </tr>\n    <tr>\n      <th>victory</th>\n      <td>0.151398</td>\n    </tr>\n    <tr>\n      <th>mr</th>\n      <td>0.139719</td>\n    </tr>\n    <tr>\n      <th>melbourne</th>\n      <td>0.124684</td>\n    </tr>\n    <tr>\n      <th>former</th>\n      <td>0.123354</td>\n    </tr>\n    <tr>\n      <th>saviour</th>\n      <td>0.109907</td>\n    </tr>\n    <tr>\n      <th>president</th>\n      <td>0.109415</td>\n    </tr>\n    <tr>\n      <th>member</th>\n      <td>0.105209</td>\n    </tr>\n    <tr>\n      <th>gabriel</th>\n      <td>0.102497</td>\n    </tr>\n    <tr>\n      <th>dumped</th>\n      <td>0.102497</td>\n    </tr>\n    <tr>\n      <th>presidency</th>\n      <td>0.102497</td>\n    </tr>\n    <tr>\n      <th>decisive</th>\n      <td>0.097239</td>\n    </tr>\n    <tr>\n      <th>pleased</th>\n      <td>0.097239</td>\n    </tr>\n    <tr>\n      <th>elected</th>\n      <td>0.093161</td>\n    </tr>\n    <tr>\n      <th>picked</th>\n      <td>0.093161</td>\n    </tr>\n    <tr>\n      <th>ill</th>\n      <td>0.093161</td>\n    </tr>\n    <tr>\n      <th>happy</th>\n      <td>0.089829</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_firstdoc.sort_values(by=[\"tfidf\"], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1678792659832,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "J9cPBdJtf8ow",
    "outputId": "f7e4adf1-f54d-4a1c-f442-000df2353a72",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.805843Z",
     "start_time": "2024-03-20T14:51:07.802674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            tfidf\nfarmer        0.0\nfast          0.0\nfatah         0.0\nfatality      0.0\nfate          0.0\nfather        0.0\nfaulkner      0.0\nfavour        0.0\nfavourable    0.0\nfavourite     0.0\nfawzi         0.0\nfazalur       0.0\nfbi           0.0\nfear          0.0\nfeat          0.0\nfeature       0.0\nfebruary      0.0\nfedera        0.0\nfederal       0.0\nzone          0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>farmer</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>fast</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>fatah</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>fatality</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>fate</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>father</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>faulkner</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>favour</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>favourable</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>favourite</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>fawzi</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>fazalur</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>fbi</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>fear</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>feat</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>feature</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>february</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>federa</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>federal</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>zone</th>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_firstdoc.sort_values(by=[\"tfidf\"], ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffMVuiV2dBCV"
   },
   "source": [
    "Notice that only certain words have scores. This is because our first document does not contain all of the top 3000 tokens which then show up as zeroes. Notice that the word “a” is missing from this list. This is possibly due to internal pre-processing of CountVectorizer where it removes single characters.\n",
    "\n",
    "The more common the word across documents, the lower its score and the more unique a word is to our first document the higher the score. So it’s working as expected except for the mysterious a that was chopped off."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4xBOrddm3u7q"
   },
   "source": [
    "<font color=\"green\"> **Question**: Please comment briefly on the relevance of these words with respect to the document content.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Answer\n",
    "The words with the highest TF-IDF scores are the most relevant to the document content. They are the words that are most unique to the document and least common in the corpus. In this case the word \"club\" has a score of 0.466\n",
    "The word club appears 5 times in the document and is not a really common word among general literature.\n",
    "The word farmer TF-IDF of 0, because it appears in the document 0 times."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pONBQI8F3u7q"
   },
   "source": [
    "## Document-document similarity using scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JUquDZi53u7q"
   },
   "source": [
    "In this section, you will write the commands to compute a document-document similarity matrix over the above documents, in scikit-learn.\n",
    "\n",
    "Please use a processing [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) and a [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and compute the *cosine similarities* between all documents.  \n",
    "\n",
    "Note: With Tfidftransformer you will systematically compute word counts using CountVectorizer and then compute the Inverse Document Frequency (IDF) values and only then compute the TF-IDF scores.\n",
    "\n",
    "With Tfidfvectorizer on the contrary, you will do all three steps at once. Under the hood, it computes the word counts, IDF values, and TF-IDF scores all using the same dataset.\n",
    "\n",
    "General guideline re. how to use Tfidftransformer over Tfidfvectorizer :\n",
    "\n",
    "- If you need the term frequency (term count) vectors for different tasks, use Tfidftransformer.\n",
    "- If you need to compute TF-IDF scores on documents within your “training” dataset, use Tfidfvectorizer\n",
    "- If you need to compute TF-IDF scores on documents outside your “training” dataset, use either one, both will work.\n",
    "\n",
    "<font color=\"green\">**Question**: At the end, you will be asked to display the five most similar documents to the one you selected above, and compare the 1st and the 5th best results.</font>\n",
    "\n",
    "You can use inspiration from: \n",
    " * the above code\n",
    " * https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.XkK2ceFCe-Y\n",
    " * https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n",
    " * https://stackoverflow.com/questions/12118720/python-TF-IDF-cosine-to-find-document-similarity\n",
    " * https://markhneedham.com/blog/2016/07/27/scitkit-learn-tfidf-and-cosine-similarity-for-computer-science-papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1678792659832,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "9yC9hlqO3u7q",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.808623Z",
     "start_time": "2024-03-20T14:51:07.806370Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1678792659832,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "8vi2v7Ml3u7q",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.810502Z",
     "start_time": "2024-03-20T14:51:07.809010Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(use_idf=True, max_features=3000)\n",
    "pipe = Pipeline(steps=[('pre', processor), ('tfidf', tfidf)])  # the 'processor' was defined above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tPKeR2Rj3u7r"
   },
   "source": [
    "<font color='green'>**Question**: Please write a function called `find_similar` which receives a `tfidf_matrix` with all similarity scores between documents, and the `index` of a document in the collection, and returns the `top_n` most similar documents to it using cosine similarity.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1678792659832,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "7sxkbsD13u7r",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:07.813054Z",
     "start_time": "2024-03-20T14:51:07.811209Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_similar(tfidf_matrix, index, top_n=5):\n",
    "    cosine_similarities = linear_kernel(tfidf_matrix[index:index + 1], tfidf_matrix).flatten()\n",
    "    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n",
    "    return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BUnaIpje3u7r"
   },
   "source": [
    "<font color=\"green\">**Question**: Using the data from the Pandas form created above, please use \"fit\" and \"transform\" to generate the matrix of all document similarites called \"tfidf_matrix\". -- How long do these two operations take on your computer?  -- Please explain briefly in your own words what is the difference between \"fit\" and \"transform\".</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1678792659833,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "ym6Labpm3u7r",
    "outputId": "86187d87-310d-47fd-e492-1e26d224c77a",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:10.021581Z",
     "start_time": "2024-03-20T14:51:07.813627Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davebrunner/.local/share/virtualenvs/TSM_AnTeDe-RXa4k3O7/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to fit and transform: 2.2061450481414795 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "tfidf_matrix = pipe.fit_transform(data_df['processed'])\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time to fit and transform: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Answer\n",
    " The difference is that fit is used to learn the vocabulary from the input data and transform is used to encode the input data into a document-term matrix."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7fWaEBWW3u7r"
   },
   "source": [
    "<font color=\"green\">**Question**: Using `find_similar` and the `tfidf_matrix` please display the five most similar documents to the one you selected above, with their scores, comment them, and compare the 1st and the 5th best results.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1678792659833,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "V-pVWIh43u7r",
    "outputId": "afc0e3c3-55da-4906-df26-779671d0baae",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:10.025045Z",
     "start_time": "2024-03-20T14:51:10.022354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Document 246 with similarity score 0.1280477164417746\n",
      "The AFL's all-time leading goalkicker, Tony Lockett, will decide within the next week if he will make a comeback. Lockett has told the Sydney Swans he is interested in coming out of retirement and placing himself in this month's pre-season draft. Lockett retired at the end of the 1999 season and will turn 36 in March. Swans chief executive Kelvin Templeton says the club would welcome Lockett back. \"We're not putting any undue pressure on him,\" Mr Templeton said. \"The approach really came from Tony to us, rather than the other way.\" Mr Templeton says if Lockett does make a comeback, the club would not expect him to play every game. \"He certainly could play a role, albeit a reduced role from the one the fans knew him to hold a couple of years back,\" he said. \n",
      "-------------------------------------\n",
      "Document 130 with similarity score 0.08050558261090161\n",
      "The condition of former Indonesian dictator Suharto has improved, a day after the 80-year-old former ruler was put on an intravenous drip and given oxygen to assist his breathing. Doctors performed a series of tests early today and said Suharto's condition had picked up slightly since yesterday. \"He is still attached to an IV drip, but the doctors said 'Bapak' (father's) condition is much better than yesterday's,\" a staff member told AFP on the condition of anonymity. \"The doctors are still talking to his  children,\" he said. Suharto fell ill on Sunday when he and his family received some 100 visitors, including ex-ministers and former vice presidents at his family house for celebrations to mark the Muslim festival of Eid-al-Fitr. The former president ruled Indonesia for 32 years before he was forced from office in 1998. He has been fitted with a pacemaker and suffered at least one slight stroke as well as periodic breathing and urinary complications. He underwent an emergency appendectomy on February 24 this year. The staff said doctors had planned on hospitalising Suharto on Sunday, but Monday's test result showed he could be treated at home. \"His breathing rhythm is normal and unlike yesterday, he does not required an oxygen mask,\" the staff member added. Suharto has been charged with embezzlling 5.775 trillion rupiah ($AUD1.102 billion) of public funds during his time in office. But he has repeatedly failed to appear in court to answer the charges with his lawyers arguing that he is too ill to stand trial. \n",
      "-------------------------------------\n",
      "Document 269 with similarity score 0.07744667552986828\n",
      "The Prime Minister, John Howard, has revealed he will go to Indonesia for a summit meeting with Indonesian President Megawati Sukarnoputri. There have been talks underway since Mr Howard was re-elected on the timing and venue for the summit. Mr Howard has now revealed he expects to travel to Indonesia for the top level meeting in February or March. It will be his second visit to Jakarta within a year. The two leaders met in Jakarta in August shortly after President Megawati took on the role. Australia and Indonesia are co-hosting an international summit on people smuggling issues in February and those issues are expected to again be a key part of the bilateral talks. Australia and Indonesia are also discussing the resumption of military ties. President Megawati signalled the relationship between the two nations had strengthened by sending a congratulatory letter to Mr Howard after the election. \n",
      "-------------------------------------\n",
      "Document 250 with similarity score 0.07408726049578357\n",
      "Israel launched massive air raids across the West Bank and Gaza Tuesday, piling pressure on Yasser Arafat with a rocket strike on  a police post next to his offices, after Prime Minister Ariel Sharon branded his administration a \"sponsor of terrorism\". Israeli F-16 warplanes launched a series of strikes on Gaza City, while Apache helicopters fired rockets on Palestinian security offices in Khan Yunis in the southern Gaza Strip and on the West Bank towns of Salfit and Tulkarem. They also fired missiles on a security post just metres from Mr Arafat's offices in Ramallah, but the Palestinian leader, who was in his office at the time, was unhurt. But two policemen were slightly wounded, officials said. Israeli army spokesman Brigadier General Ron Kitrey said Mr Arafat was not targeted. Two people were killed in the Gaza strikes and around 120 injured, half of them schoolboys, Palestinian hospital officials said. The attacks came as Israel's Foreign Minister Shimon Peres said he did not believe Israeli forces would take direct action against the Palestinian  leader. The strikes also came a day after Mr Sharon, furious that Mr Arafat had not stopped hardline Islamic groups, who killed two dozen Israelis in devastating suicide attacks at the weekend, ordered his forces to blast symbols of Mr Arafat's  power. Gunships destroyed Mr Arafat's three helicopters in Gaza City, while bulldozers ploughed up the runway at Gaza international airport used by Mr Arafat for his frequent travels abroad. Palestinian officials called Mr Sharon's campaign an attempt to topple Mr Arafat and destroy his self-rule Palestinian Authority. Mr Arafat told CNN television that Mr Sharon was trying to torpedo his own crackdown on terrorism with the airstrikes. \"He doesn't want me to succeed, and for this he is escalating his military activities against our towns, our cities, our establishments,\" the Palestinian leader said. French Foreign Minister Hubert Vedrine accused Israel of conducting a deliberate policy aimed at eliminating Mr Arafat. \"Arafat has been weakened by the harassment of the Israeli army ... and as a result people are using his weakness as an argument to say that since he can not re-establish order in his own camp, he should in some way be eliminated.\" However, Britain's Prime Minister Tony Blair and US President George W Bush expressed \"sympathy\" with Israel and called on all sides \"to do anything they can to stabilise the situation\". Mr Sharon's hard words and air strikes opened major divisions in his cross-party government, with left-wing Mr Peres denouncing what he called a bid during Monday's emergency cabinet meeting to cause \"the downfall of the Palestinian Authority\". The region had been braced for a huge Israeli retaliation after three Palestinian suicide bombers from the hardline Islamic movement Hamas killed 25 people on Saturday and Sunday in the suicide attacks in Jerusalem and Haifa. Mr Sharon made a national address after blasting Gaza City and Jenin in the West Bank on Monday, accusing Mr Arafat of having \"chosen the path of terrorism\" and  being \"the greatest obstacle to peace and stability in the Middle East\". Mr Peres said the move by Mr Sharon's dominant right-wingers \"in effect means Israeli policy is based purely on force with no political hope\". Public radio said Mr Peres had called all the ministers from his Labour Party for a special meeting Wednesday to discuss the fallout of the strikes and Mr Sharon's accusation that Mr Arafat was \"responsible for everything that has happened here\". Chief Palestinian negotiator Saeb Erakat, speaking after Mr Sharon's speech Monday evening, said the words amounted to a \"declaration of war\". He called on the United States and Europe to rein in Mr Sharon and dispatch international observers to oversee the spiralling conflict. \n",
      "-------------------------------------\n",
      "Document 122 with similarity score 0.06830524847904705\n",
      "At least four people, including two policemen, have been killed during an attempted coup in Haiti overnight. Armed commandos had stormed the national palace in the Haitian capital after midnight, local time and seized control of radio communications equipment. The attackers, understood to be former members of the Haitian military, fired at security guards as they entered the palace - the official residence of President Jean Bertrand Aristide. But the President was at another home in the capital Port-au-Prince during the attack. It is understood some of the gunmen have been arrested and the Haitian Government says it is now back in control. President Aristide was deposed in a coup 10 years ago, but was returned to power in 1994 after a United States invasion. He was recently re-elected for five years. \n"
     ]
    }
   ],
   "source": [
    "most_similar = find_similar(tfidf_matrix, 111)\n",
    "\n",
    "for (index, cosine_similarity) in most_similar:\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f\"Document {index} with similarity score {cosine_similarity}\")\n",
    "    print(data_df['text'].iloc[index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DC0mkVoe3u7s"
   },
   "source": [
    "<font color='green'>**Question**: Could you also use the dot product instead of the cosine similarity in the `find_similar` function?  Please answer in the following box.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Answer\n",
    "I would not recommend to do that, since the dimension of the matrix is huge 300 x 4892 therefore its a very sparce matrix and the dot product would not be a good measure of similarity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(300, 3000)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:10.029907Z",
     "start_time": "2024-03-20T14:51:10.028071Z"
    }
   },
   "execution_count": 28
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "O_8zazOh3u7s"
   },
   "source": [
    "## Building a search engine using Gensim\n",
    "\n",
    "<font color='green'>**Question**: Using the [tutorial on Topics and Transformations from Gensim](https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html#sphx-glr-auto-examples-core-run-topics-and-transformations-py), please implement a method that returns the documents most similar to a given query.\n",
    "    \n",
    "Use [Gensim's TF-IDF Model](https://radimrehurek.com/gensim/models/tfidfmodel.html) to build the model and the [MatrixSimilarity function](https://radimrehurek.com/gensim/similarities/docsim.html#gensim.similarities.docsim.MatrixSimilarity) to measure cosine similarity between documents.</font>\n",
    "\n",
    "<font color='green'>Please write a query of your own (5-10 words), retrieve the 5 most similar documents, and comment the result.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1678792659833,
     "user": {
      "displayName": "Daniel Perruchoud",
      "userId": "15604693075568907580"
     },
     "user_tz": -60
    },
    "id": "Etqoo3qd3u7s",
    "outputId": "b239e443-60e4-4105-f3d5-46622c40e873",
    "ExecuteTime": {
     "end_time": "2024-03-20T14:51:12.461904Z",
     "start_time": "2024-03-20T14:51:10.030423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      " The Prime Minister, John Howard, has revealed he will go to Indonesia for a summit meeting with Indonesian President Megawati Sukarnoputri. There have been talks underway since Mr Howard was re-elected on the timing and venue for the summit. Mr Howard has now revealed he expects to travel to Indonesia for the top level meeting in February or March. It will be his second visit to Jakarta within a year. The two leaders met in Jakarta in August shortly after President Megawati took on the role. Australia and Indonesia are co-hosting an international summit on people smuggling issues in February and those issues are expected to again be a key part of the bilateral talks. Australia and Indonesia are also discussing the resumption of military ties. President Megawati signalled the relationship between the two nations had strengthened by sending a congratulatory letter to Mr Howard after the election. \n",
      "----------\n",
      " The Prime Minister has thrown his full support behind the Governor-General, Dr Peter Hollingworth. Child rights campaigners have accused Dr Hollingworth of trying to cover-up child abuse allegations at a Toowoomba Anglican school when he was Archbishop of Brisbane. In a statement released earlier this week, the Governor-General said the allegations were unfounded, but there are continuing calls for Dr Hollingworth to resign. But Mr Howard says he has confidence in the Governor-General. \"I don't have any direct knowledge of this [matter but] I've talked to him about it and I've tried to form a judgment,\" Mr Howard said. \"The criticism made is that he's involved in a cover-up, well there's no evidence of that, that's ridiculous.\" \n",
      "----------\n",
      " Qantas management and unions representing the airline's maintenance workers will meet again today after marathon talks last night failed to resolve a wage dispute. Unions are fighting a proposed 12 to 18 month wage freeze and to secure a better career structure for their 2,500 employees. Bill Shorten of the Australian Workers Union (AWU) says the unions will not rest until a satisfactory outcome is reached. \"After eight hours, the AWU and AMWU are still talking to Qantas, we will resume tomorrow morning at 11am [AEDT] in the Industrial Relations Commission to see if we can't work through this position our members now find ourselves in,\" he said last night. Meanwhile, Ansett workers will sing Christmas carols in front of the Prime Minister's Kirribilli residence in Sydney this morning to remind John Howard about their owed entitlements. The Transport Workers Union (TWU) will hold a 24-hour picket outside Kirribilli House and says about 16,000 workers and their families are facing a bleak Christmas. The News South Wales secretary of the TWU, Tony Sheldon, says the Government promised to deliver about $195 million in entitlements. Mr Sheldon says the financial situation for many workers has reached crisis point. \"There's been very little delivered by this Government, a lot of promises, a lot of noise was made before the federal election but very little in substance. \"It's important John Howard delivers for the tourism community, for the Ansett workers and for the Australian community generally,\" Mr Sheldon said. \n",
      "----------\n",
      " The royal commission into the building industry will hold its first public hearings in Melbourne today. The Howard Government established the commission in July prior to calling the federal election, prompting union claims of a political witch-hunt. But Royal Commissioner Terence Cole QC has stressed the independence of his inquiry. He will examine claims of corruption, coercion and anti-competitive behaviour in the industry. Unions had initially refused to cooperate with the inquiry, but key union figures, including Construction, Forestry, Mining and Energy Union (CFMEU) secretary Martin Kingham, have been summonsed to give evidence. A finding is not expected for 12 months. \n",
      "----------\n",
      " Federal Labor MP Carmen Lawrence says there is a lot of momentum within the party for the ALP to change its policy on asylum seekers. Dr Lawrence says maintaining the policy will lose the sympathy of some sections of the community who have thought very carefully about the issues. She says it will also annoy others who supported the Coalition's stance and see the ALP as compromised. The Member for Fremantle says Labor did not suffer in the polls after it differentiated itself from the Coalition in 1996 and 1998. \"We committed to native title, we refused the extinguishment options that Howard put forward,\" she said. \"We indicated our willingness to give an official apology on behalf of the nation to the Stolen Generations and we didn't lose a single vote, in fact we came the nearest to winning an election after having been nearly obliterated in 1996.\" \n"
     ]
    },
    {
     "data": {
      "text/plain": "[(269, 0.3460057344551972),\n (73, 0.2086701715594594),\n (203, 0.1903326282562786),\n (206, 0.11152047286012765),\n (92, 0.10785900090766765)]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data_df['text']\n",
    "cv = CountVectorizer(max_features=3000)  # keep only the 3000 most frequent words in the corpus\n",
    "\n",
    "\n",
    "def get_most_similar_document(query: str):\n",
    "    local_text = pd.concat([text, pd.Series([query])])\n",
    "    local_processed = processor.transform(local_text)\n",
    "\n",
    "    cv = CountVectorizer(max_features=3000)  # keep only the 3000 most frequent words in the corpus\n",
    "    word_count_vector = cv.fit_transform(local_processed)\n",
    "    tfidf_matrix = tfidf_transformer.transform(cv.transform(local_processed))\n",
    "    most_similar = find_similar(tfidf_matrix, len(local_text) - 1)\n",
    "    [print(\"----------\\n\", text.iloc[index]) for (index, _) in most_similar]\n",
    "    return most_similar\n",
    "\n",
    "get_most_similar_document(\"john howard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms3Fdokq3u7t"
   },
   "source": [
    "## End of Lab 4\n",
    "Please make sure all cells have been executed, save this completed notebook, compress it to a *zip* file, and upload it to [Moodle](https://moodle.msengineering.ch/course/view.php?id=1869)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
